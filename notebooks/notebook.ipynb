{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in file: results/2024/04.19/13-45-48/4/cifar100_fixed_ewc/stderr-2024-04-19-16-49.txt, line: 8, content: Exception ignored in: <function Logger.__del__ at 0x14c6d9302560>\n",
      "Found in file: results/2024/04.19/13-45-48/3/cifar100_fixed_ewc/stderr-2024-04-19-16-48.txt, line: 8, content: Exception ignored in: <function Logger.__del__ at 0x1490da6ea560>\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import re\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Define the directory path and search pattern\n",
    "directory_path = \"results/2024/04.19/13-45-48\"\n",
    "search_text = \"Exception ignored in: <function Logger.__del__\"\n",
    "\n",
    "# Find files matching the pattern\n",
    "files = Path(directory_path).rglob(pattern=\"stderr*\")\n",
    "\n",
    "# Define a regular expression pattern to match the search text\n",
    "pattern = re.compile(search_text)\n",
    "\n",
    "broken_params = []\n",
    "# Iterate through each file and search for the text\n",
    "for file_path in files:\n",
    "    with file_path.open(\"r\") as file:\n",
    "        for line_number, line in enumerate(file, start=1):\n",
    "            if pattern.search(line):\n",
    "                print(\n",
    "                    f\"Found in file: {file_path}, line: {line_number}, content: {line.strip()}\"\n",
    "                )\n",
    "                yaml_file = file_path.parent.parent / \".hydra\" / \"overrides.yaml\"\n",
    "                broken_params.append(yaml.safe_load(yaml_file.open(\"r\")))\n",
    "                break\n",
    "# pprint(broken_params)\n",
    "\n",
    "# grouped_data = defaultdict(list)\n",
    "\n",
    "# # Iterate through the data and group it based on the first element of each sublist\n",
    "# for sublist in broken_params:\n",
    "#     key = sublist[0]\n",
    "#     grouped_data[key].append(sublist[1:])\n",
    "\n",
    "# # Convert defaultdict to dict\n",
    "# grouped_data = dict(grouped_data)\n",
    "\n",
    "# pprint(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "params = np.asarray(broken_params)\n",
    "\n",
    "\n",
    "def delete_to_pandas(name, arr):\n",
    "    return map(lambda x: x.replace(name, \"\"), arr)\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"training.vcreg.reg_layers=\",\n",
    "    \"training.vcreg.var_weight=\",\n",
    "    \"training.vcreg.cov_weight=\",\n",
    "]\n",
    "df = pd.DataFrame(\n",
    "    [delete_to_pandas(name, params[:, idx]) for idx, name in enumerate(names)]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(\n",
    "    columns={\n",
    "        0: \"reg_layers\",\n",
    "        1: \"var_weight\",\n",
    "        2: \"cov_weight\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reg_layers': 'fc$', 'var_weight': '1.74', 'cov_weight': '0.64'},\n",
       " {'reg_layers': 'fc$', 'var_weight': '0.64', 'cov_weight': '12.8'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(broken_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\"tunnels-ssl/05.17\")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict[\"test/avg_acc_tag\"])\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "    {\"avg_acc_tag\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    ")\n",
    "config_df = pd.json_normalize(runs_df[\"config\"])\n",
    "df = pd.concat([runs_df.drop(columns=[\"config\"]), config_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training.approach.name</th>\n",
       "      <th>data.exemplars.num_exemplars</th>\n",
       "      <th>training.vcreg.reg_layers</th>\n",
       "      <th>misc.results_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ewc</td>\n",
       "      <td>0</td>\n",
       "      <td>fc$</td>\n",
       "      <td>results/2024/05.17/17-05-54/0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ewc</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>results/2024/05.17/17-06-00/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0</td>\n",
       "      <td>fc$</td>\n",
       "      <td>results/2024/05.17/17-05-54/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>results/2024/05.17/17-06-00/0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>2000</td>\n",
       "      <td>fc$</td>\n",
       "      <td>results/2024/05.17/17-05-54/3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>finetuning</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>results/2024/05.17/17-06-00/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>lwf</td>\n",
       "      <td>0</td>\n",
       "      <td>.*after_relu</td>\n",
       "      <td>results/2024/05.17/17-05-54/2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lwf</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>results/2024/05.17/17-06-00/3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training.approach.name  data.exemplars.num_exemplars  \\\n",
       "73                    ewc                             0   \n",
       "67                    ewc                             0   \n",
       "72             finetuning                             0   \n",
       "69             finetuning                             0   \n",
       "66             finetuning                          2000   \n",
       "68             finetuning                          2000   \n",
       "70                    lwf                             0   \n",
       "0                     lwf                             0   \n",
       "\n",
       "   training.vcreg.reg_layers              misc.results_path  \n",
       "73                       fc$  results/2024/05.17/17-05-54/0  \n",
       "67                       NaN  results/2024/05.17/17-06-00/2  \n",
       "72                       fc$  results/2024/05.17/17-05-54/1  \n",
       "69                       NaN  results/2024/05.17/17-06-00/0  \n",
       "66                       fc$  results/2024/05.17/17-05-54/3  \n",
       "68                       NaN  results/2024/05.17/17-06-00/1  \n",
       "70              .*after_relu  results/2024/05.17/17-05-54/2  \n",
       "0                        NaN  results/2024/05.17/17-06-00/3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = df[\"model.network\"] == \"no_last_relu\"\n",
    "df[condition][\n",
    "    [\n",
    "        \"training.approach.name\",\n",
    "        \"data.exemplars.num_exemplars\",\n",
    "        \"training.vcreg.reg_layers\",\n",
    "        \"misc.results_path\",\n",
    "    ]\n",
    "].sort_values(\n",
    "    by=[\n",
    "        \"training.approach.name\",\n",
    "        \"data.exemplars.num_exemplars\",\n",
    "        \"training.vcreg.reg_layers\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/tscratch/people/plghpiotr/cl-adaptation/notebooks\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
